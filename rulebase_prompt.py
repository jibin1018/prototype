"""
ê·œì¹™ ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ íŒŒì„œ
ê¸°ì¡´ parser.pyì˜ ê·œì¹™ ê¸°ë°˜ ë¡œì§ì„ í™œìš©í•˜ì—¬ êµ¬í˜„
"""

import json
import re
from typing import Dict, List, Optional
from datetime import datetime
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class RulebasePromptParser:
    """ê·œì¹™ ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ íŒŒì„œ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.current_year = datetime.now().year
        self.mappings = self._init_mappings()
        print("ğŸ“‹ Rulebase íŒŒì„œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _init_mappings(self) -> Dict:
        """ë§¤í•‘ í…Œì´ë¸” ì´ˆê¸°í™” - ì‹¤ì œ ë°ì´í„°ì— ë§ê²Œ ìˆ˜ì •"""
        return {
            "regions": {
                "ì„œìš¸": ["ì„œìš¸", "seoul", "ê°•ë‚¨", "ê°•ë¶", "ë§ˆí¬", "ìš©ì‚°", "ê°•ì„œ", "ì†¡íŒŒ"],
                "ê²½ê¸°ë„": ["ê²½ê¸°", "ìˆ˜ì›", "ì„±ë‚¨", "ì•ˆì–‘", "ë¶€ì²œ", "ê³ ì–‘", "í‰íƒ", "ìš©ì¸", "ë¶„ë‹¹", "íŒêµ"],
                "ë¶€ì‚°": ["ë¶€ì‚°", "busan", "í•´ìš´ëŒ€", "ë‚¨êµ¬", "ë™ë˜"],
                "ì¸ì²œ": ["ì¸ì²œ", "incheon", "ì†¡ë„", "ì—°ìˆ˜"],
                "ëŒ€ì „": ["ëŒ€ì „", "daejeon", "ìœ ì„±", "ì„œêµ¬"],
                "ëŒ€êµ¬": ["ëŒ€êµ¬", "daegu", "ìˆ˜ì„±", "ë‹¬ì„œ"],
                "ê´‘ì£¼": ["ê´‘ì£¼", "gwangju", "ë¶êµ¬", "ì„œêµ¬"],
                "ìš¸ì‚°": ["ìš¸ì‚°", "ulsan", "ë‚¨êµ¬", "ë™êµ¬"]
            },
            "industry_domains": {
                "ê¸ˆìœµ": ["ê¸ˆìœµ", "ì€í–‰", "ì¦ê¶Œ", "ë³´í—˜", "ì¹´ë“œ", "í•€í…Œí¬", "finance", "banking"],
                "ê³µê³µ": ["ê³µê³µ", "ì •ë¶€", "ê´€ê³µì„œ", "ê³µê¸°ì—…", "government"],
                "ì œì¡°": ["ì œì¡°", "manufacturing", "ìƒì‚°", "ê³µì¥"],
                "ìœ í†µ": ["ìœ í†µ", "retail", "ì´ì»¤ë¨¸ìŠ¤", "ì‡¼í•‘ëª°", "ë¬¼ë¥˜"],
                "ì—ë„ˆì§€": ["ì—ë„ˆì§€", "ì „ë ¥", "ë°œì „", "í•œì „", "ì „ê¸°"],
                "ì¼ë°˜": ["ì¼ë°˜", "ê¸°ì—…", "íšŒì‚¬"]
            },
            "industry_knowledge": {
                "ì¸í”„ë¼": ["ì¸í”„ë¼", "infrastructure", "ì„œë²„", "ë„¤íŠ¸ì›Œí¬"],
                "ë³´í—˜": ["ë³´í—˜", "insurance", "ìƒë³´", "ì†ë³´", "ë³´í—˜ì‚¬"],
                "ì€í–‰": ["ì€í–‰", "banking", "ì—¬ì‹ ", "ìˆ˜ì‹ "],
                "ì¦ê¶Œ": ["ì¦ê¶Œ", "securities", "íˆ¬ì", "ìì‚°ê´€ë¦¬"],
                "êµ°ì—…ë¬´": ["êµ°", "êµ­ë°©", "military", "ë³´ì•ˆ"],
                "ë©”ë””ì»¬": ["ì˜ë£Œ", "medical", "ë³‘ì›", "í—¬ìŠ¤ì¼€ì–´"],
                "ì „ë ¥": ["ì „ë ¥", "ì „ê¸°", "power", "ì—ë„ˆì§€"],
                "ê³µí†µ": ["ê³µí†µ", "ì¼ë°˜", "ë²”ìš©"]
            },
            "specializations": {
                "NE": ["ne", "ë„¤íŠ¸ì›Œí¬", "network", "ìŠ¤ìœ„ì¹˜", "ë¼ìš°í„°", "ì‹œìŠ¤ì½”", "cisco"],
                "SE": ["se", "ì‹œìŠ¤í…œ", "system", "ì„œë²„", "unix", "linux", "ë¦¬ëˆ…ìŠ¤"],
                "DVLP": ["ê°œë°œ", "development", "í”„ë¡œê·¸ë˜ë°", "ì½”ë”©", "dev", "java", "spring"],
                "DBA": ["dba", "ë°ì´í„°ë² ì´ìŠ¤", "database", "db", "ì˜¤ë¼í´", "mysql"],
                "ë³´ì•ˆ": ["ë³´ì•ˆ", "security", "ì •ë³´ë³´í˜¸", "í•´í‚¹", "ë°©í™”ë²½"],
                "AA": ["aa", "application", "ì–´í”Œë¦¬ì¼€ì´ì…˜", "ì•±", "ì•„í‚¤í…ì²˜"],
                "PMO": ["pmo", "í”„ë¡œì íŠ¸", "project", "ê´€ë¦¬"],
                "OP": ["op", "ìš´ì˜", "operation", "ëª¨ë‹ˆí„°ë§", "ì‹œìŠ¤í…œìš´ì˜"],
                "QA": ["qa", "í…ŒìŠ¤íŠ¸", "test", "í’ˆì§ˆë³´ì¦"],
                "WAS": ["was", "ì›¹ì„œë²„", "tomcat", "weblogic"],
                "íšŒê³„": ["íšŒê³„", "accounting", "ì¬ë¬´", "ì„¸ë¬´"]
            },
            "talent_levels": {
                "ê³ ê¸‰": ["ê³ ê¸‰", "senior", "ì‹œë‹ˆì–´", "ì „ë¬¸ê°€", "expert"],
                "ì¤‘ê¸‰": ["ì¤‘ê¸‰", "middle", "ë¯¸ë“¤", "ê²½ë ¥"],
                "ì´ˆê¸‰": ["ì´ˆê¸‰", "junior", "ì£¼ë‹ˆì–´", "ì‹ ì…", "entry"],
                "ë“±ê¸‰ë¬´ê´€": ["ë“±ê¸‰ë¬´ê´€", "ë¬´ê´€", "ìƒê´€ì—†ìŒ"]
            },
            "tech_stacks": {
                "ë„¤íŠ¸ì›Œí¬": ["cisco", "juniper", "hp", "switch", "router", "firewall", "ì‹œìŠ¤ì½”", "í™”ì›¨ì´"],
                "ì„œë²„OS": ["linux", "unix", "windows", "centos", "ubuntu", "redhat", "aix", "ë¦¬ëˆ…ìŠ¤"],
                "ë°ì´í„°ë² ì´ìŠ¤": ["oracle", "mysql", "postgresql", "mssql", "mongodb", "ì˜¤ë¼í´"],
                "ê°œë°œì–¸ì–´": ["java", "python", "c++", "javascript", "php", "c#", "spring"],
                "í´ë¼ìš°ë“œ": ["aws", "azure", "gcp", "docker", "kubernetes"],
                "ë³´ì•ˆ": ["ips", "ids", "waf", "dlp", "apm", "ë°©í™”ë²½"],
                "ì›¹ì„œë²„": ["apache", "nginx", "tomcat", "weblogic", "jboss"],
                "ê¸°íƒ€": ["ncrm", "ê°€ìƒí™”", "ì´ì¤‘í™”", "dns", "proxy"]
            }
        }
    
    def parse(self, user_input: str) -> Dict:
        """ë©”ì¸ íŒŒì‹± í•¨ìˆ˜"""
        logger.info(f"ğŸ“‹ Rulebase íŒŒì‹± ì‹œì‘: {user_input}")
        
        try:
            result = self._create_empty_result()
            text = user_input.lower()
            
            # 1. ë‚˜ì´ ì •ë³´ ì¶”ì¶œ
            age_info = self._extract_age_info(text, user_input)
            result.update(age_info)
            
            # 2. ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
            result["residence"] = self._find_best_match(text, "regions")
            result["industry_domain"] = self._find_best_match(text, "industry_domains")
            result["industry_knowledge"] = self._find_best_match(text, "industry_knowledge")
            result["specialization"] = self._find_best_match(text, "specializations")
            
            # 3. ê²½ë ¥ ì¶”ì¶œ
            result["experience_years"] = self._extract_experience_years(text)
            
            # 4. ì¸ì¬ ë“±ê¸‰ ì¶”ì¶œ
            result["talent_level"] = self._extract_talent_levels(text)
            
            # 5. ê¸°ìˆ  ìŠ¤íƒ ì¶”ì¶œ
            result["skills"] = self._extract_tech_skills(text)
            
            # 6. ë²¡í„° í•„ë“œ ìƒì„±
            result["vector_fields"] = self._generate_vector_fields(user_input, result)
            
            # 7. ì¡°ê±´ ë¶„ë¥˜
            result["requirement_type"] = self._classify_requirements(text)
            
            # 8. ë¯¸ë¶„ë¥˜ í•„ë“œ
            result["unknown_fields"] = self._extract_unknown_fields(text)
            
            logger.info("âœ… Rulebase íŒŒì‹± ì™„ë£Œ")
            return result
            
        except Exception as e:
            logger.error(f"âŒ íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
            return self._create_empty_result()
    
    def _create_empty_result(self) -> Dict:
        """ë¹ˆ ê²°ê³¼ êµ¬ì¡° ìƒì„±"""
        return {
            "age_min": None,
            "age_max": None,
            "age": None,
            "residence": None,
            "industry_domain": None,
            "industry_knowledge": None,
            "specialization": None,
            "experience_years": None,
            "talent_level": None,
            "skills": None,
            "vector_fields": {
                "professional_competency": None,
                "technical_expertise": None,
                "leadership_experience": None,
                "scale_complexity": None,
                "compliance_security": None,
                "industry_specialization": None
            },
            "requirement_type": [],
            "unknown_fields": []
        }
    
    def _extract_age_info(self, text: str, original_text: str) -> Dict:
        """ë‚˜ì´ ì •ë³´ ì¶”ì¶œ - ì™„ì „í•œ ë²„ì „"""
        age_info = {}
        
        try:
            # êµ¬ì²´ì  ë‚˜ì´ íŒ¨í„´
            age_patterns = [
                r'(\d{1,2})ì„¸',
                r'(\d{1,2})ì‚´',
                r'age\s*(\d{1,2})',
            ]
            
            for pattern in age_patterns:
                match = re.search(pattern, text)
                if match:
                    age = int(match.group(1))
                    if 20 <= age <= 65:
                        age_info["age"] = age
                        break
            
            # ë‚˜ì´ ë²”ìœ„ íŒ¨í„´
            range_match = re.search(r'(\d{1,2})\s*~\s*(\d{1,2})ì„¸', text)
            if range_match:
                min_age = int(range_match.group(1))
                max_age = int(range_match.group(2))
                age_info["age_min"] = min_age
                age_info["age_max"] = max_age
            
            # 30ëŒ€, 40ëŒ€ ë“± ì²˜ë¦¬
            decade_match = re.search(r'(\d{1})0ëŒ€', text)
            if decade_match:
                decade = int(decade_match.group(1))
                if 2 <= decade <= 6:
                    age_info["age_min"] = decade * 10
                    age_info["age_max"] = decade * 10 + 9
            
            # ì´ìƒ/ì´í•˜ ì²˜ë¦¬
            above_match = re.search(r'(\d{1,2})\s*ì´ìƒ', text)
            if above_match:
                age_info["age_min"] = int(above_match.group(1))
            
            below_match = re.search(r'(\d{1,2})\s*ì´í•˜', text)
            if below_match:
                age_info["age_max"] = int(below_match.group(1))
                
        except ValueError as e:
            logger.warning(f"ë‚˜ì´ íŒŒì‹± ì˜¤ë¥˜: {e}")
        
        return age_info
    
    def _find_best_match(self, text: str, category: str) -> Optional[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ ì¹´í…Œê³ ë¦¬ë³„ ìµœì  ë§¤ì¹­"""
        try:
            mappings = self.mappings.get(category, {})
            
            for key, keywords in mappings.items():
                for keyword in keywords:
                    if keyword.lower() in text:
                        return key
        except Exception as e:
            logger.warning(f"ë§¤ì¹­ ì˜¤ë¥˜ ({category}): {e}")
        
        return None
    
    def _extract_experience_years(self, text: str) -> Optional[int]:
        """ê²½ë ¥ë…„ìˆ˜ ì¶”ì¶œ"""
        try:
            patterns = [
                r'(\d{1,2})\s*ë…„\s*ì´ìƒ',
                r'(\d{1,2})\s*ë…„ì°¨',
                r'ê²½ë ¥\s*(\d{1,2})\s*ë…„',
                r'(\d{1,2})\s*year',
            ]
            
            for pattern in patterns:
                match = re.search(pattern, text)
                if match:
                    years = int(match.group(1))
                    if 0 <= years <= 30:
                        return years
        except ValueError as e:
            logger.warning(f"ê²½ë ¥ë…„ìˆ˜ íŒŒì‹± ì˜¤ë¥˜: {e}")
        
        return None
    
    def _extract_talent_levels(self, text: str) -> Optional[List[str]]:
        """ì¸ì¬ ë“±ê¸‰ ì¶”ì¶œ"""
        try:
            levels = []
            
            for level, keywords in self.mappings["talent_levels"].items():
                for keyword in keywords:
                    if keyword in text:
                        levels.append(level)
                        break
            
            return levels if levels else None
        except Exception as e:
            logger.warning(f"ì¸ì¬ë“±ê¸‰ íŒŒì‹± ì˜¤ë¥˜: {e}")
            return None
    
    def _extract_tech_skills(self, text: str) -> Optional[List[str]]:
        """ê¸°ìˆ  ìŠ¤íƒ ì¶”ì¶œ"""
        try:
            skills = []
            
            for category, tech_list in self.mappings["tech_stacks"].items():
                for tech in tech_list:
                    if tech.lower() in text:
                        skills.append(tech)
            
            return list(set(skills)) if skills else None
        except Exception as e:
            logger.warning(f"ê¸°ìˆ ìŠ¤íƒ íŒŒì‹± ì˜¤ë¥˜: {e}")
            return None
    
    def _generate_vector_fields(self, original_text: str, parsed_data: Dict) -> Dict:
        """ë²¡í„° í•„ë“œ ìƒì„±"""
        vector_fields = {
            "professional_competency": None,
            "technical_expertise": None,
            "leadership_experience": None,
            "scale_complexity": None,
            "compliance_security": None,
            "industry_specialization": None
        }
        
        try:
            text = original_text.lower()
            
            # ì „ë¬¸ ì—­ëŸ‰
            competencies = []
            competency_keywords = {
                "ìœ ì§€ë³´ìˆ˜": ["ìœ ì§€ë³´ìˆ˜", "maintenance", "ìš´ì˜", "ê´€ë¦¬"],
                "êµ¬ì¶•": ["êµ¬ì¶•", "ì„¤ì¹˜", "êµ¬í˜„", "ê°œë°œ", "ì„¤ê³„"],
                "ì •ê¸°ì ê²€": ["ì ê²€", "ëª¨ë‹ˆí„°ë§", "ê°ì‹œ"],
                "íŠ¸ëŸ¬ë¸”ìŠˆíŒ…": ["ì¥ì• ", "ë¬¸ì œí•´ê²°", "troubleshooting"],
                "ì‹œìŠ¤í…œ ìš´ì˜": ["ì‹œìŠ¤í…œ ìš´ì˜", "ìš´ì˜ ê²½í—˜"]
            }
            
            for comp, keywords in competency_keywords.items():
                for keyword in keywords:
                    if keyword in text:
                        competencies.append(comp)
                        break
            
            if competencies:
                vector_fields["professional_competency"] = ", ".join(competencies)
            
            # ê¸°ìˆ  ì „ë¬¸ì„±
            if parsed_data.get("specialization"):
                spec_map = {
                    "NE": "ë„¤íŠ¸ì›Œí¬ ì¸í”„ë¼ ì „ë¬¸ì„±",
                    "SE": "ì‹œìŠ¤í…œ ì—”ì§€ë‹ˆì–´ë§ ì „ë¬¸ì„±",
                    "DBA": "ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ ì „ë¬¸ì„±",
                    "DVLP": "ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ ì „ë¬¸ì„±",
                    "ë³´ì•ˆ": "ì •ë³´ë³´ì•ˆ ì „ë¬¸ì„±",
                    "OP": "ì‹œìŠ¤í…œ ìš´ì˜ ì „ë¬¸ì„±",
                    "AA": "ì•„í‚¤í…ì²˜ ì„¤ê³„ ì „ë¬¸ì„±",
                    "PMO": "í”„ë¡œì íŠ¸ ê´€ë¦¬ ì „ë¬¸ì„±",
                    "QA": "í’ˆì§ˆê´€ë¦¬ ì „ë¬¸ì„±",
                    "WAS": "ì›¹ì„œë²„ ê´€ë¦¬ ì „ë¬¸ì„±"
                }
                vector_fields["technical_expertise"] = spec_map.get(
                    parsed_data["specialization"], "ê¸°ìˆ  ì „ë¬¸ì„±"
                )
            
            # ì‚°ì—… ì „ë¬¸ì„±
            if parsed_data.get("industry_domain"):
                industry_spec = f"{parsed_data['industry_domain']} ë¶„ì•¼"
                if parsed_data.get("industry_knowledge"):
                    industry_spec += f", {parsed_data['industry_knowledge']} ì „ë¬¸ì„±"
                vector_fields["industry_specialization"] = industry_spec
            
            # ê·œëª¨/ë³µì¡ì„±
            scale_keywords = ["ëŒ€ê·œëª¨", "enterprise", "ê¸€ë¡œë²Œ", "ë³µì¡í•œ", "ì´ì¤‘í™”", "í´ëŸ¬ìŠ¤í„°"]
            for keyword in scale_keywords:
                if keyword in text:
                    vector_fields["scale_complexity"] = "ëŒ€ê·œëª¨ ì‹œìŠ¤í…œ ê²½í—˜"
                    break
            
            # ë¦¬ë”ì‹­
            leadership_keywords = ["íŒ€ì¥", "ë¦¬ë”", "ë§¤ë‹ˆì €", "ê´€ë¦¬", "lead", "ì£¼ë„"]
            for keyword in leadership_keywords:
                if keyword in text:
                    vector_fields["leadership_experience"] = "íŒ€ ë¦¬ë”ì‹­ ê²½í—˜"
                    break
            
            # ì»´í”Œë¼ì´ì–¸ìŠ¤/ë³´ì•ˆ
            compliance_keywords = ["ë³´ì•ˆ", "ì»´í”Œë¼ì´ì–¸ìŠ¤", "ê·œì œ", "ì¸ì¦", "ê°ì‚¬"]
            for keyword in compliance_keywords:
                if keyword in text:
                    vector_fields["compliance_security"] = "ë³´ì•ˆ/ì»´í”Œë¼ì´ì–¸ìŠ¤ ê²½í—˜"
                    break
                    
        except Exception as e:
            logger.warning(f"ë²¡í„° í•„ë“œ ìƒì„± ì˜¤ë¥˜: {e}")
        
        return vector_fields
    
    def _classify_requirements(self, text: str) -> List[str]:
        """ìš”êµ¬ì‚¬í•­ ë¶„ë¥˜"""
        try:
            requirements = []
            
            req_keywords = {
                "ê¸´ê¸‰": ["ê¸´ê¸‰", "urgent", "ì¦‰ì‹œ", "ë¹¨ë¦¬"],
                "ì¥ê¸°": ["ì¥ê¸°", "long-term", "ì§€ì†", "ì•ˆì •"],
                "í”„ë¡œì íŠ¸": ["í”„ë¡œì íŠ¸", "project", "êµ¬ì¶•"],
                "ìš´ì˜": ["ìš´ì˜", "operation", "ìœ ì§€ë³´ìˆ˜"]
            }
            
            for req_type, keywords in req_keywords.items():
                for keyword in keywords:
                    if keyword in text:
                        requirements.append(req_type)
                        break
            
            return requirements
        except Exception as e:
            logger.warning(f"ìš”êµ¬ì‚¬í•­ ë¶„ë¥˜ ì˜¤ë¥˜: {e}")
            return []
    
    def _extract_unknown_fields(self, text: str) -> List[str]:
        """ë¯¸ë¶„ë¥˜ í•„ë“œ ì¶”ì¶œ"""
        try:
            unknown_fields = []
            
            unknown_keywords = {
                "ì•¼ê°„ì‘ì—…": ["ì•¼ê°„", "night", "ë°¤"],
                "ì¶œì¥ê°€ëŠ¥": ["ì¶œì¥", "travel", "ì´ë™"],
                "ìƒì£¼ê·¼ë¬´": ["ìƒì£¼", "onsite", "í˜„ì¥"],
                "ì™¸ê·¼ê°€ëŠ¥": ["ì™¸ê·¼", "field", "ë°©ë¬¸"],
                "ì›ê²©ê·¼ë¬´": ["ì¬íƒ", "remote", "ì›ê²©"]
            }
            
            for field, keywords in unknown_keywords.items():
                for keyword in keywords:
                    if keyword in text:
                        unknown_fields.append(field)
                        break
            
            return unknown_fields
        except Exception as e:
            logger.warning(f"ë¯¸ë¶„ë¥˜ í•„ë“œ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return []